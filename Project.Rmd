---
# Document information

title: "LSTAT2170 - Time series"
subtitle: "Final Project"

institute: "Universit√© catholique de Louvain"
faculty: "Louvain School of Statistics"
department: ""

context: "Florida Natural Gas Deliveries Analysis"
date: \today

authors:
  - "Lionel Lamy"
  - "1294-1700"

# ---
colorlinks: false
bordercolorlinks: true

linkcolor: "black"
urlcolor:  "black"
citecolor: "blue"

linkbordercolor: "black"
urlbordercolor: "black"
citebordercolor: "blue"

links-as-notes: false
# ---
# header-includes:
output:
  pdf_document:
    template: template/markdown.tex
    toc: yes
    toc_depth: 3
    fig_caption: yes
---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  echo = F,
  eval = T,

  warning = F,
  message = F,
  comment = NA,

  out.width = "85%",
  fig.align = "center",
  fig.path = "resources/figs/",

  tidy = TRUE,
  tidy.opts = list(width.cutoff = 65),
  
  digits=3
)

def_hook <- knitr::knit_hooks$get("output")
knitr::knit_hooks$set(output = function(x, options) {
  out <- def_hook(x, options)
  out <- gsub(x = out, pattern = "```", replacement = "", fixed = T)
  return(paste(out, collapse = "\n"))
})
```

```{r requirements, appendix=TRUE, cache=FALSE}
#' Import facility functions in a separate attached environment
#' To keep our global clean

facilities <- new.env()
source("./resources/scripts/fonctionsSeriesChrono.R", local = facilities)

# Please check the github repository
source("./resources/scripts/sarima_model_selection.R", local = facilities)
source("./resources/scripts/ts_custom_plots.R", local = facilities)
source("./resources/scripts/ts_significance_test.R", local = facilities)
source("./resources/scripts/ts_on_sample_prediction.R", local = facilities)

attach(facilities, name = "facilities")

```

```{r data_import, appendix=TRUE}
# Import the gas dataset
gas <- read.table("./resources/data/gasflorida.txt", header = F)
gas <- ts(gas, start = 1991, frequency = 12)

# Define some useful variables
gas.start <- tsp(gas)[1]
gas.end <- tsp(gas)[2]
gas.freq <- tsp(gas)[3]
gas.t <- seq(gas.start, to = gas.end, length = length(gas))
gas.xaxp <- c(floor(gas.start), floor(gas.end), floor(gas.end - gas.start))

```

# Introduction

In this project one will focus on the analysis of real data. These data are the U.S. Natural Gas State Data and concern the monthly quantity of natural gas delivered to residential and commercial consumers (excluding vehicle fuel) in Florida. Aggregated on a monthly basis, the data are presented in millions of cubic feet (MMcf[^1]) and cover the period from January 1991 to August 1999.

[^1]: \quad"Mcf" means 1,000 cubic feet of natural gas; "MMcf" means 1,000 Mcf.

The beginning of this report will start with a first visual discovery of the dataset. Then, a set of transformations will be applied to stabilize the variance, remove possible trends and seasonality. Next, one will analyze the autocorrelation and partial autocorrelation functions in order to have a first intuition on the type of model to fit. Following this, several methods such as a significance test of the coefficients, an analysis of the residuals by a Ljung-Box test or the evaluation of the predictive capacity "on sample" will allow to establish which model would be the most appropriate for the data. The final objective is to be able to give a prediction interval for future values over roughly one year.

# Data discovery

Considering the data to be an additive model $Y_t = T_t + S_t + \epsilon_t$, one can have a first insight by decomposing the series into trend ($T$), seasonal ($S$) and random ($\epsilon$) pieces. A plot containing the undecomposed data is available in the [appendix](#F1).

```{r plot_decompose, appendix=TRUE}
# Plot the decomposition of the data (see ts_custom_plot.R)
plot.decompose.ts(gas, main = "Decomposition of the deliveries of natural gas", cex.lab = .9, cex.axis = .95, xaxp = gas.xaxp)

```
\vspace{-.5em}

The first obvious observation one can make by looking at just the first line is one is dealing with seasonal data. Indeed, the third row shows an almost perfect seasonality with maximum values at the beginning of each year and minimum values towards the middle.  These results are hardly surprising given the nature of the data. Indeed, it seems normal that a greater quantity of gas is used during winter and that gas consumption decreases during summer. Looking at the second line of the graph, one see that the data do not really seem to vary except in 1996-1997 when a decrease is noticeable. A closer look at the first line shows this phenomenon. 

Another interesting way to present the data is to display the evolution of the deliveries by stacking the years line by line. The outcome is fortunately the same. One notice a strong seasonality (since the lines all follow the same pattern) as well as a small decrease that seems to start from 1997 (colored dashed lines). Moreover, the lines seems to remain relatively close to each other and there is no drastic change in variance over time.

```{r plot_superposed, appendix=TRUE}
# Plot the superposed view of the data (see ts_custom_plot.R)
plot.superposed.ts(gas, title = "Superposed monthly deliveries of gas", xlab = "Month", ylab = "MMcf", dashed_thick_from = c(6, 8), xlim = c(0, 12))

```

# Box-Jenkins

The previous observations do not require stabilizing the variance by any transformation of the data. On the other hand, as one aim to examine the correlation structure of the residuals, (weak) stationarity need to achieved. Meaning that it is necessary to deseasonalize and delinearize the data in order to go further with the visual analysis.

## Deseasonalize and detrend

For this purpose, the method of (iterated) differences will be used. Considering that $Y_t$ is the time series at period $t$, then the first difference at lag $k$ is $\bigtriangledown_k\ Y_t := Y_t - Y_{t-k}$. As a first step, the latter operation is applied on the data at lag 1 to remove the linear trend. This process is next repeated at a lag equal to the periodicity, ie. the value 12 since the data is collected monthly and the seasonality is annual.

The resulting time series is therefore shifted by $k = 13$ periods. 

```{r, deseasonalize_detrend, appendix=TRUE}
# Remove global trend
gas.1 <- diff(gas, lag=1, differences = 1)
# Remove the seasonality using lag 12 as we have monthly data
gas.2 <- diff(gas.1, lag = 12, differences = 1)

```

```{r, fig.height=4.5, appendix=TRUE}
# Removed trend
plot(gas.1, main = "Detrended time series", sub="First difference at lag k=1", xaxp = gas.xaxp)
abline(reg = lm(gas.1 ~ tail(gas.t, -1)), col = "red", lty = 1, xlab="Year", ylab="Y")
abline(h=0, col = rgb(0, 0, 1, .7), lty = 2)
legend("topright", legend = c("Linear trend", "Horizontal line"), col = c("red","blue"), cex = .8, lty = c(1,2))

```

One observe in the figure above that once the data is differentiated, the linear trend is much less pronounced but there still is a visible periodicity. This particularity seems to be corrected on the second graph below as the time series now appears to be random. Even if by plotting a linear regression (in red) one can see that the trend is not quite equal to zero, the slope is flat enough to consider the time series to be (weakly) stationary.

```{r, fig.height=4.5, appendix=TRUE}
# Removed trend and seasonality
plot(gas.2, main = "Detrended and deseasonalized time series", xaxp = gas.xaxp, sub="First difference at lag k=12", xlab="Year", ylab="Y")
abline(reg = lm(gas.2 ~ tail(gas.t, -12-1)), col = "red", lty = 1)
abline(h=0, col = rgb(0, 0, 1, .7), lty = 2)
legend("topright", legend = c("Linear trend", "Horizontal line"), col = c("red","blue"), cex = .8, lty = c(1,2))

```
 
\pagebreak

## ACF and PACF

Now that the data is differenced and assumed to be stationary, one can examine the correlation structure and have an intuition of the values to feed into the model. The auto-correlation and partial auto-correlation functions will serve this purpose. 

To recall, the former describes how well the present value is correlated with its past values while the latter does the same but removing the linear dependence at intermediate lags. Both assume the data to be stationary and the lagged values to act like white noise. Thus, confidence intervals are constructed [assuming a normal distribution](#F4), with $Z_\alpha$ the normal quantile at level $\alpha$ and $T$ the length of the data :
$$
CI = \sbk{\frac{Z_{\alpha/2}}{\sqrt{T}}\ ;\ \frac{Z_{1-\alpha/2}}{\sqrt{T}}}
$$
In the figures below, one notice that both ACF and PACF tend towards zero. The values fall below the confidence interval after lag 1 for the ACF and lag 2 (or 1 according to the degree of tolerance) for the PACF. The simultaneous look on the ACF and PACF might suggest an ARMA(0,1) or ARMA(1,1) on a yearly basis.
\vspace{-.5em} <!-- Need space -->
```{r plot_acf_pacf_yearly, appendix=TRUE, fig.show="hold", out.width="49%", fig.width=5.5}
# Plot the ACF and PACF, yearly basis
plot.acf.pacf(gas.2, lag.max = length(gas.2), simplify = F, linked_by_line = F, titles=c("Yearly ACF", "Yearly PACF"))

```
\vspace{-1em} <!-- Need space -->
Although kind of predictable, the presence of significant correlations at lag 1 is nevertheless intriguing. The transformations performed have only removed a deterministic element of seasonality and a stochastic component could indeed remain. Analyzing the ACF and PACF on a monthly basis, i.e. between lag [0 and 1[ also reveal a significant value at first lag. Note that in the case of the ACF, the value at lag 0 is always 1. On a monthly basis, one might thus move with an ARMA(1,1).
\vspace{-.5em} <!-- Need space -->
```{r plot_acf_pacf_monthly, appendix=TRUE, fig.show="hold", out.width="49%", fig.width=5.5}
# Plot the ACF and PACF, monthly basis
plot.acf.pacf(gas.2, lag.max = gas.freq-1, simplify = F, linked_by_line = T, titles=c("ACF", "PACF"), sub="Up to lag 1")

```
\vspace{-.5em} <!-- Need space -->
\pagebreak
# Model selection

In consideration of the aforementioned elements, it was decided to proceed with an SARIMA model. Before continuing, one should yet provide a small definition. An SARIMA model is an Autoregressive Integrated Moving Average model that supports the direct modeling of a Seasonal component (S). Meaning we have 4 more elements ($P$, $D$, $Q$) and $s$, where $P$ is the seasonal AR order, $D$ the seasonal difference order, $Q$ the seasonal MA order and $s$ the seasonal period. 

Putting them together, one obtain a model called SARIMA($p$, $d$, $q$)$\times$($P$, $D$, $Q$)$_s$ if the time series $X_t$ can be transformed into a stationary series without trend or seasonality. 
$$
Y_t = \bigtriangledown^d \bigtriangledown^D_s X_t = (1-B)^d\ (1-B^s)^D\ X_t
$$
And where the latter can be modelised in the form of a stationary ARMA process
$$
\phi(B)\ \Phi(B^s)\ Y_t = \theta(B)\ \Theta(B^s)\ \epsilon_t
$$
where $B$ is the backshift operator, $\bigtriangledown$ the difference operator and where $\phi(z)$, $\Phi(z)$, $\theta(z)$ and $\Theta(z)$ are the generating polynomial of respectively, an AR($p$), AR($P$), MA($q$) and MA($Q$) process.

## Selection

Following the visual analysis of the previous section, it is expected to obtain SARIMA models of orders up to 1. However, to figure out which model would be the best one will iterate over all possible SARIMA models with parameters value up to 2.

To evaluate the effectiveness of the different models, the Akaike information criterion (AIC) will primarily be used. However, since the AIC tends to overestimate the number of parameters needed, the Bayesian information criterion (BIC), which penalizes a bit more the number of parameters, will provide a secondary information.

The results below describe the top 3 models found, from best to worst. First, one notice via the AICR[^2] that the models have very close results. The winning model has an AIC of 1229, a BIC of 1241 and is composed of 4 parameters. The second one has a higher AIC of only 0.064 and a lower BIC of 2.447 (relative to the first one) but has only 3 parameters. The last model is somewhat less interesting since the increase in AIC is more important and it has as much parameters as the best one.

[^2]: Akaike information criterion relative to the best model. 

\begin{figure}[hb]
\centering
\hspace{-3em}
\begin{BVerbatim}
```{r model_selection, appendix=TRUE, comment=""}
# Model comparison via AIC. (see sarima_model_selection.R)
sarima.model.selection(gas, max.pq = c(2,2), max.PQ = c(1,1), d = 1, D = 1, top=3, return.best = F)

```
\end{BVerbatim}
\end{figure}

```{r models_definition}
# Explicitely define models to have a Training set with summary()
model.1 = arima(gas, order = c(1, 1, 1), seasonal = list(order = c(1, 1, 1), period = gas.freq))
model.2 = arima(gas, order = c(1, 1, 1), seasonal = list(order = c(0, 1, 1), period = gas.freq))
model.3 = arima(gas, order = c(2, 1, 1), seasonal = list(order = c(0, 1, 1), period = gas.freq))

```


As an additional information, the log-likelihood ($\mathcal{L}$) of the models are respectively : \
`r round(logLik(model.1),3)`, `r round(logLik(model.2),3)` and `r round(logLik(model.3),3)` and the AIC is computed via $-2\mathcal{L}\,+ 2\,(P+1)$.\
Also, a more complete summary is available [in appendix](#O1) for each model.

# Models comparison and validation

Now that a selection of models is established, one need to check if they are valid and correctly fitted. To do so, one will first perform an univariate and two-sided significance test (based on normal approximations) of the coefficients. Then, evaluate the predictive ability "on sample" and finally, after the choice of the final model, do an analysis of the residuals by a Portmanteau (Ljung-box) test. 

## Coefficients

In the same order as displayed in the previous section:

\begin{figure}[h]
\centering
\hspace{-3em}
\begin{BVerbatim}
```{r significance_tests,appendix=TRUE, strip.white=TRUE}
# Test the coefficients of each model (see ts_significance_test.R)
significance.test(model.1, T)
significance.test(model.2, T)
significance.test(model.3, T)

```
\end{BVerbatim}
\end{figure}

Thanks to the indicators in parentheses, it is easy to see which coefficients are significant and to what degree. First, for the model with the lowest AIC (1) one cannot reject the hypothesis that the coefficient sar1 ($\Phi_1$) is statistically different from zero, even with an $\alpha = 0.10$. The same is observed for the third model with ar2 ($\phi_2$).

## Predictive power

Lets now continue with a comparison of the predictive power of each model. To this end, each model will be fed with $Y_{1:t}$ where $Y_{1:t}$ is the set of data up to $t$. At each step, one step ahead  will be predicted (ie. $\hat{Y}_{t+1}$) and the operation repeated with $t$ starting at 80% of the series and until the end is reached. In other terms, $t = 0.8T$ to $T-1$. Finally, one can calculate the MSE of each models by comparing with the last 20% observed data.

```{r on_sample_prediction, appendix=TRUE}
#' MSE and predictions for the last 20% (see ts_on_sample_prediction.R) 
model.1.osp = on.sample.prediction(gas, order = c(1, 1, 1), 
              seasonal = list(order = c(1, 1, 1), period = gas.freq))
model.2.osp = on.sample.prediction(gas, order = c(1, 1, 1), 
              seasonal = list(order = c(0, 1, 1), period = gas.freq))
model.3.osp = on.sample.prediction(gas, order = c(2, 1, 1), 
              seasonal = list(order = c(0, 1, 1), period = gas.freq))

```
```{r plot_on_sample_predictions, appendix=TRUE, fig.height=3.8}

# Adapt the predictions to the plot of the time series
models.osp.ts = function(values) ts(values, end=gas.end, frequency = gas.freq)

par(mar=c(4,4,2.2,4))
# Plot the predictions
plot(models.osp.ts(tail(gas, 24)), lwd=2, main="On sample predictions", ylab="MMcf", xlab="Year", 
     ylim=c(min(tail(gas, 24))-100, max(tail(gas, 24))+300))
lines(models.osp.ts(model.1.osp$pred), col=rgb(1,0,0,.7))
lines(models.osp.ts(model.2.osp$pred), col=rgb(0,1,0,.7))
lines(models.osp.ts(model.3.osp$pred), col=rgb(0,0,1,.7))
legend("topright", legend=c("Original data","(1,1,1)x(1,1,1)[12]", "(1,1,1)x(0,1,1)[12]", "(2,1,1)x(0,1,1)[12]"), col=1:4, lty=1, cex=.6)

```
\pagebreak

Although not perfect, the models manage to follow the global trend pretty well but models 2 (green) and 3 (blue) seem to perform slightly better than the first one (red). In fact, their MSE are lower with respectively 30142 and 29607, what corresponds to a decrease of more than 8% compared to 32830.

\begin{table}[h]
\centering
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{Model 1} & \textbf{Model 2} & \textbf{Model 3} \\ \midrule
32 830           & 30 142           & 29 607           \\ \bottomrule
\end{tabular}
\end{table}

Those results lead to choose the second model. This one being the most parsimonious, it only loses 0.064 points of AIC, has only 1.8% more MSE than the third model and in view of the significance test seems to be the most relevant. The latter can mathematically be written as :

\begin{center}
S-ARIMA(1,1,1)$\times$(0,1,1)$_{12}$\\
$
  (1-\phi_1B)(1-B)^1(1-B^{12})^1\ Y_t = (1+\theta_1B)(1+\Theta_1B^{12})\ \epsilon_t
$
\end{center}
with coefficients, $\phi_1 = 0.453$, $\theta_1 = -0.832$, and $\Theta_1 = -1.000$.

## Ljung-Box

As a last test, one will check the autocorrelation of the residuals of the model via a portmanteau test, more specifically a Ljung-box test. One test the null hypothesis that the residuals are not different from white noise, up to lag $K = \sqrt{T}$. 
$$H_0: \rho_{\epsilon}(1)=...= \rho_{\epsilon}(K) = 0$$
$$H_1: \rho_{\epsilon}(1)=...= \rho_{\epsilon}(K) \ne 0$$
```{r plot_ljungbox, appendix=TRUE, fig.height=4.5}
# Box.test of the residuals
plot.ljungbox(resid(model.2), floor(sqrt(length(gas))))

```
\vspace{-1em}
As the p-values are all well above the threshold, one cannot reject the null hypothesis. This is convenient because it means that there is no correlation in the residuals. The same test was performed for the residuals squared and the [result](#F3) is similar. Also, a more complete figure which includes the ACF of the residuals is available in the [appendix](#F2).

# Predictions
## Introduction

Now that a model has been established and validated, one would like to plot a prediction interval for at least one season to get an idea of the future evolution. Assuming the normality of the prediction errors, the prediction intervals are constructed via :
$$
\widehat{Y}_{T+k} \pm Z_{1-\alpha/2}\times \hat{S_{k}}
$$
with $Z_\alpha$ the normal quantile at level $\alpha = 0.05$, $\widehat{Y}_{T+k}$ the predicted value at step $T+k$ and $\hat{S_k}$ an estimate of the $k$-step ahead standard deviation of the forecast distribution. In the case of an arima model, the latter is computed by Kalman Filtering (1960).[^4]

However, before concluding we also want to experiment with another way of predicting data that is part of the exponential smoothing methods. Exponential smoothing methods produce forecasts where recent observations have a greater weight than past ones. In other words, the more recent the observation, the higher the associated weight. Therefore, it would be interesting to compare one of these methods. In this case, as the data contains both trend and seasonal components, the Holt (1957) and Winters (1960) one will be used. One define it, for an additive model, with $p$ the seasonality:
$$
\widehat{Y}_{t+k} = a_t + kb_t + s_{[t-p+1+(k-1)\ \text{mod}\ p]}
$$
where $a_t$, $b_t$ and $s_t$ are given by:
$$
\begin{split}
a_t & = \alpha(Y_t - s_{t-p}) + (1-\alpha) (a_{t-1} + b_{t-1}) \\
b_t & = \beta(a_t - a_{t-1}) + (1-\beta)\ b_{t-1} \\
s_t & = \gamma(Y_t - a_t) + (1-\gamma)\ s_{t-p}
\end{split}
$$
and correspond to respectively the level, the trend and the seasonal component with their smoothing parameters $\alpha$, $\beta$ and $\gamma$. Those parameters are determined by minimizing the squared prediction error. The full output is available in [the appendix](#O2) as well as a complete [on-sample prediction](#F7). With the gas deliveries time series, the latter are equal to:

\begin{table}[h]
\centering
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{$\alpha$} & \textbf{$\beta$} & \textbf{$\gamma$} \\ \midrule
0.5598            & 0.0153           & 0.5127            \\ \bottomrule
\end{tabular}
\end{table}

\pagebreak 

## Results

The two figures below represent the prediction intervals for 16 future values, one year and one quarter. On the left, the predictions obtained with the S-ARIMA model and on the right those obtained by the Holt-Winters method. As the two predictions are very similar, the graphs below are "zoomed in" but are available in their entirety in the [appendix](#F6).

Both approaches predict that gas deliveries in Florida for the year 2000 are expected to remain at about the same level as in previous years, or to decline very slightly. In addition, the 95% prediction intervals remain relatively narrow. However, the Holt-Winters method shows a more noticeable decrease and more tolerant intervals the farther away from the last observed year.

```{r plot_predictions_side_by_side, appendix=TRUE, fig.show="hold", out.width="49%", fig.width=5.5}
# Predictions with model 2 and Holt-winters, zoomed
md = plot.n.ahead.predictions(gas, model.2, n=gas.freq+4, before=20, xlab="Year", ylab="MMcf")
hw = plot.n.ahead.predictions(gas, model.2, n=gas.freq+4, before=20, holtwinters = T, xlab="Year", ylab="MMcf")

```

To facilitate comparison and highlight these observations, the graph below displays the two prediction intervals together.

```{r plot_predictions_comparison, appendix=TRUE}
(function(){
plot(md$pred, lwd=2, ylim=c(min(md$pred-1000), max(md$pred+800)), main="Predictions comparison\nSarima vs HoltWinters", col=1, xlab="Year", ylab="MMcf")
lines(md$pred + 1.96*md$se, lty="dashed", col=1)
lines(md$pred - 1.96*md$se, lty="dashed", col=1)
lines(hw[,"fit"], col=4, lwd=2)
lines(hw[, "upr"], lty="dashed", col=4)
lines(hw[, "lwr"], lty="dashed", col=4)
legend("topleft", legend=c("(1,1,1)x(0,1,1)[12]", "Holt-Winters"), col=c(1,4), lty=c(1,1), lwd=c(2,2), cex=.7)
})()
```

[^4]: More precisely, $\hat{S_k} = \tilde{S_k}\times \sigma^2$ with $\tilde{S_k}$ the unscaled standard deviation of the prediction errors, and $\sigma^2$ the variance of the model residuals. See the R documentation and source code of stats:::predict.Arima.

\pagebreak
# Conclusion

At first glance, the presence of seasonality and a slight downward trend was immediately noticed. Since we are not dealing with financial data, the possibility of an ARCH model was immediately ruled out. Then, in order to push the visual analysis beyond the simple decomposition, it was necessary to differentiate the data set. 

The observation of the autocorrelation and partial autocorrelation functions allowed us to move towards S-ARIMA models with orders that do not go too high. An automated selection (by iteration) of models according to the AIC was then performed. The latter brought to light 3 models whose efficiency, predictive capacity on sample and the significance of their coefficients were tested. Only the second model, an SARIMA(1,1,1)x(0,1,1)[12] was retained. This was the most parsimonious model, with no coefficients that were not statistically different from zero and with a low in-sample prediction error and AIC. Afterwards, a Ljung-Box test on the residuals of the model showed that it was able to correctly capture the components of the data set.

Finally, prediction intervals for a duration of a little more than one year in the future have been performed for this model but also compared to an alternative non-parametric method which generally performs well. The predictions agree that for the year 2000, no structural change is expected and that a simple and slight decrease in shipments is to be expected. However, the possibility of unforeseen changes should not be ruled out. 

As a final word, this work demonstrates that although we have tools that automate tasks, it is important to perform a preliminary and visual analysis and to understand the underlying challenges behind the models used.  


<!------>

\newpage
\appendix

# Appendix

```{r, appendix=TRUE}
#' ============================================

```

\bigskip
\begin{mdframed}[style=thicc, frametitle=Note, frametitlebackgroundcolor=black!30]
  For reproducibility purposes, the complete project containing the source code, the full sized figures and the results is available on \href{https://github.com/lamylio/LSTAT2170-Project}{github.com/lamylio/LSTAT2170-Project}.
\end{mdframed}

## Figures

### Plot of the data{#F1}
```{r appendix_1_plot, appendix=TRUE}
# Plot the complete dataset non decomposed
plot(gas, main = "Gas deliveries in Florida", xaxp = gas.xaxp, ylab="MMcf")

```

### TSDiag (Portemanteau test){#F2}

```{r appendix_2_tsdiag, appendix=TRUE, fig.height=5.5}
# TSDiag : Ljung-Box test with ACF
tsdiag(model.2, gof.lag=floor(sqrt(length(gas))))

```

### Ljung-Box test of the squared residuals{#F3}

```{r appendix_3_ljung, appendix=TRUE}
# Ljung-Box test of the squared residuals
plot.ljungbox(resid(model.2)**2, floor(sqrt(length(gas))), 
              title="Ljung-Box of the squared residuals")

```


### QQ-Plot of the differenciated time series{#F4}
```{r appendix_4_qq_diff, appendix=TRUE}
# QQPlot of the residuals of model 2
qqnorm(gas.2, sub="Detrended and deseasonalized")
qqline(gas.2, col="red")

```

### QQ-Plot of the residuals of model 2{#F5}
```{r appendix_5_qq_res, appendix=TRUE}
# QQPlot of the residuals of model 2
qqnorm(resid(model.2), sub="Model (1,1,1)x(0,1,1)[12]")
qqline(resid(model.2), col="red")

```

### Predictions not zoomed{#F6}

```{r appendix_6_ahead, appendix=TRUE, out.width="49%", fig.width=5.5, fig.show="hold", results='hide'}
# Predictions with model 2 and Holt-winters, zoomed
plot.n.ahead.predictions(gas, model.2, n=gas.freq+4, before=length(gas))
plot.n.ahead.predictions(gas, model.2, n=gas.freq+4, before=length(gas), holtwinters = T)

```

### Holt-Winters on sample predictions{#F7}

```{r appendix_7_holt, appendix=TRUE}
# Plot the filtering of HW model
plot(HoltWinters(gas), ylab="MMcf", xlab="Year")
legend("topright", legend = c("Observed", "Holt-Winters"), lty=1, col=c(1,2), cex=.7)

```


## Output

### Summaries of models{#O1}

\begin{figure}[H]
\centering
\begin{BVerbatim}
```{r appendix_out_1, appendix=TRUE}
# library(forecast)
round(forecast::accuracy(model.1), 3)
round(forecast::accuracy(model.2), 3)
round(forecast::accuracy(model.3), 3)
```
\end{BVerbatim}
\end{figure}

### Holt-Winters{#O2}

\begin{figure}[H]
\centering
\hspace{-3em}
\begin{BVerbatim}
```{r appendix_out_2, appendix=TRUE}
# HoltWinters coefficients and parameters
HoltWinters(gas)

```
\end{BVerbatim}
\end{figure}

\pagebreak

## Code
The below section is automatically generated and tidied. Visit the repository for more readability.

```{r appendix_pre}
# remotes::install_github('yihui/formatR')
library(formatR)
```


```{r appendix_code, eval=FALSE, echo=TRUE, ref.label=knitr::all_labels(appendix==T)}

```
